{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "570d11f7",
   "metadata": {},
   "source": [
    "# Morphism 4: Classification and Model Training: \n",
    "\n",
    "Function: F_{CMT} = Constructs, fits, balances, and utilizes classification models to best classify transactions as Fraud. \n",
    "\n",
    "Risk Function: R_{CMT} = Loss functions are utilzied to improve accuracy and decrease frequency of incorrect classifications. \n",
    "\n",
    "Parameters: Model Choices and Balancing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a149ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import scipy\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bafab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r trainDF\n",
    "%store -r cleaned_trainDF_Isolation\n",
    "%store -r cleaned_trainDF_Mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9ff58",
   "metadata": {},
   "source": [
    "# Data Preprocessing (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25649cc7",
   "metadata": {},
   "source": [
    "<p style=\"font-size:10px\">Our group utilized two forms of outlier analysis Mahalanobis Outlier Detection and Isolation Forest Anomaly Detection. After utilizing both measures, datasets were saved according to what was remaining after removing outliers. These were then both applied to the original dataset to only keep transactions whose TransactionID remained in both of the newly produced datasets with outlier removed. </p>\n",
    "\n",
    "<p style=\"font-size:10px\">In our CART Tree model, after intitial performance analysis we applied SMOTE to balance the dataset as our elementary data analysis provided much evidence that the dataset is unbalanced. A XGBoost model was then ran after due to non-linearity of data and the fact that XGBoost framework excels with data cotaining many empty values.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">Visualizations: CART Decision Tree Visualization (Decision Tree), Top 10 Feature Importances for CART Tree model (histogram), ROC Curve for CART Tree (line plot), Precision-Recall Curve for CART Tree (line plot), Calibration Curve for CART Tree (line plot), Top 10 Feature Importances for XGBoost model (histogram), ROC Curve for XGBoost model (line plot),  Precision-Recall Curve for XGBoost model (line plot), and Calibration Curve for XGBoost model (line plot).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90040e1",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89889b4c",
   "metadata": {},
   "source": [
    "# Isolation Forest Anomaly Removal Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8126ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9789897520163566\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    155971\n",
      "           1       0.97      0.04      0.07      3475\n",
      "\n",
      "    accuracy                           0.98    159446\n",
      "   macro avg       0.97      0.52      0.53    159446\n",
      "weighted avg       0.98      0.98      0.97    159446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_cleaned_Isolation = cleaned_trainDF_Isolation.drop(columns=['isFraud'])  # Features\n",
    "y_cleaned_Isolation = trainDF.loc[cleaned_trainDF_Isolation.index, 'isFraud']  # Target\n",
    "X_train_isolation, X_test_isolation, y_train_isolation, y_test_isolation = train_test_split(X_cleaned_Isolation, y_cleaned_Isolation, test_size=0.3, random_state=0, stratify=y_cleaned_Isolation)\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=0, max_depth=10)\n",
    "model.fit(X_train_isolation, y_train_isolation)\n",
    "y_pred_isolation = model.predict(X_test_isolation)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_isolation, y_pred_isolation))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_isolation, y_pred_isolation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b3a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 1 Error Rate (False Positive Rate): 2.564579312820973e-05\n",
      "Type 2 Error Rate (False Negative Rate): 0.9628776978417266\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test_isolation, y_pred_isolation)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "type_1_error_rate = fp / (fp + tn) \n",
    "type_2_error_rate = fn / (fn + tp)\n",
    "print(f\"Type 1 Error Rate (False Positive Rate): {type_1_error_rate}\")\n",
    "print(f\"Type 2 Error Rate (False Negative Rate): {type_2_error_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557237e5",
   "metadata": {},
   "source": [
    "**Statistics: Isolation Forest Anomaly Removal Performance Analysis**\n",
    "\n",
    "<p style=\"font-size:10px\">It can be seen that after removing anomalies found in Isolation Forest within dataset, that a random forest model with test_size = 0.3 has accuracy 0.98, and has a type1 error of 2*10^-5 and a type2 error of 0.963. This indicates that a basic model run on this data struggles with False negative rates, identifying many cases of fraud as non-fraudulent.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0a758",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2061c4cf",
   "metadata": {},
   "source": [
    "# Mahalanobis Outlier Removal Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc8eafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=10, n_estimators=50, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cleaned_trainDF_Mahalanobis.drop(columns=['isFraud'])  # Features\n",
    "y = trainDF.loc[cleaned_trainDF_Mahalanobis.index, 'isFraud']  # Target\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X, y, test_size=.3, random_state=0, stratify=y)\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=0, max_depth=10)  # You can adjust n_estimators as needed\n",
    "model.fit(X_train_m, y_train_m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3fb80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[170843    120]\n",
      " [  4547   1652]]\n",
      "Accuracy: 0.9737\n",
      "Type 1 Error Rate (False Positive Rate): 0.0007019062604189211\n",
      "Type 2 Error Rate (False Negative Rate): 0.733505404097435\n"
     ]
    }
   ],
   "source": [
    "y_pred_m = model.predict(X_test_m)\n",
    "conf = confusion_matrix(y_test_m, y_pred_m)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf)\n",
    "\n",
    "accuracy = accuracy_score(y_test_m, y_pred_m)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "type_1_error_rate = fp / (fp + tn)  # False Positive Rate\n",
    "type_2_error_rate = fn / (fn + tp)  # False Negative Rate\n",
    "\n",
    "print(f\"Type 1 Error Rate (False Positive Rate): {type_1_error_rate}\")\n",
    "print(f\"Type 2 Error Rate (False Negative Rate): {type_2_error_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d17f1",
   "metadata": {},
   "source": [
    "**Statistics: Mahalanobis Outlier Removal Performance Analysis**\n",
    "\n",
    "<p style=\"font-size:10px\">It can be seen that after removing Mahalanobis outliers from the dataset, that once again accuracy is high at 0.97. The confusion matrix highlights the misclassifcation errors; with a higher false positive rate than the isolation forest, but a decently lower false-negative rate than the isolation forest. This indicates that Mahalnobis Outlier Detection and Isolation Forest Anomaly Detection have different strengths when applied to our dataset.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db58475",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb72867",
   "metadata": {},
   "source": [
    "# Removal of Outliers (Mahalanobis + Isolation Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77bb1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trainDF = trainDF.merge(cleaned_trainDF_Mahalanobis[['TransactionID']], on='TransactionID')\n",
    "filtered_trainDF = filtered_trainDF.merge(cleaned_trainDF_Isolation[['TransactionID']], on='TransactionID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015dbe5",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9494e6e",
   "metadata": {},
   "source": [
    "# CART Tree Classification + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c3fe9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CART model: 0.9741669645712996\n",
      "Classification Report for CART model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    103955\n",
      "           1       0.42      0.47      0.44      2343\n",
      "\n",
      "    accuracy                           0.97    106298\n",
      "   macro avg       0.70      0.73      0.71    106298\n",
      "weighted avg       0.98      0.97      0.97    106298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data: Define features (X) and target (y)\n",
    "X = filtered_trainDF.drop(columns=['isFraud'])  # Features (drop the target column)\n",
    "y = filtered_trainDF['isFraud']  # Target\n",
    "\n",
    "# Handle Timestamp columns (convert them to numeric if necessary)\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'datetime64[ns]' or 'Timestamp' in str(X[col].dtype):\n",
    "        X[col] = X[col].astype('int64')  # Convert datetime to int (timestamps)\n",
    "\n",
    "# Convert categorical columns to numeric using Label Encoding (for simplicity)\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object' or isinstance(X[column].dtype, pd.CategoricalDtype):\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column].astype(str))\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Replace infinite or very large values with NaN\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN values for numeric columns with column mean, and categorical columns with mode\n",
    "for col in X.columns:\n",
    "    if X[col].dtype in ['float64', 'int64']:  # For numeric columns\n",
    "        X[col] = X[col].fillna(X[col].mean())  # Assign the filled result back to the column\n",
    "    else:  # For categorical columns, fill with the most frequent value\n",
    "        X[col] = X[col].fillna(X[col].mode()[0])  # Assign the filled result back to the column\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the CART model (DecisionTreeClassifier)\n",
    "cart_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "cart_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_cart = cart_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_cart = accuracy_score(y_test, y_pred_cart)\n",
    "classification_report_cart = classification_report(y_test, y_pred_cart)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy of CART model: {accuracy_cart}\")\n",
    "print(f\"Classification Report for CART model:\\n{classification_report_cart}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8346780",
   "metadata": {},
   "source": [
    "**Statistics: Initial CART Tree Model Performance Analysis (PRE SMOTE)**\n",
    "\n",
    "<p style=\"font-size:10px\">It can be seen that using a CART Tree Model for classification is the correct move for best identifying fraudulent transactions. The CART Tree decision model excels in scenarios like this inwhich there are many interfeature relations within the dataset that play into whether a transaction is considered fraudulent or not. There are not many linear relationships in this data which is another advanatage for using the CART Tree model. There are many anomalies in the dataset even after removing outliers, and CART Tree creates exclusive paths for them. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38283bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))  # Adjust the size of the plot\n",
    "plot_tree(cart_model, \n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          feature_names=X.columns,  # Use feature names for clarity\n",
    "          class_names=['Not Fraud', 'Fraud'],  # Use class names\n",
    "          fontsize=10)\n",
    "\n",
    "plt.title(\"Decision Tree Visualization (CART Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab6109",
   "metadata": {},
   "source": [
    "**Visualization: CART Tree Model Decision Tree (PRE SMOTE)**\n",
    "\n",
    "<p style=\"font-size:10px\">This is a visuzalization of the CART Tree Model Decision Tree, and the colors refer to how the model decided to classify each transaction. Due to the complexity of this visualization, it can be noted that this dataset has a high amount of variability. Balancing (SMOTE) could lead to more clear results. It can be seen that near the top the most prevalent features are: V156, V11, V308, and Transaction_Amt, indicating high significance with regards to flagging fraud. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa555ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "cart_model.fit(X_train_res, y_train_res)\n",
    "y_pred_cart = cart_model.predict(X_test)\n",
    "accuracy_cart = accuracy_score(y_test, y_pred_cart)\n",
    "classification_report_cart = classification_report(y_test, y_pred_cart)\n",
    "print(f\"Accuracy of CART model: {accuracy_cart}\")\n",
    "print(f\"Classification Report for CART model:\\n{classification_report_cart}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8bfe3",
   "metadata": {},
   "source": [
    "**Statistics: CART Tree Model Decision Tree Performance Analysis(POST SMOTE)**\n",
    "\n",
    "<p style=\"font-size:10px\">These is the performance analysis of the CART Tree decision model after SMOTE is ran to balance the high variability within the data. Judging off the decrease in metrics for precision, recall, and f1-score across classifcation's 0 and 1, it can be seen that SMOTE introduce some noise to our data by balancing the data. For example, the f1-score went from .44 to .37 for classifier 1; this indicates that synthetic fraudulent data was added to the dataset.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">The macro averages can also be seen to display a decrease in value: this indicates that SMOTE lead to less balanced performance across all the classes once again suggesting synthetic fraudulent data was negatively applied to the balanced dataset. </p>\n",
    "\n",
    "<p style=\"font-size:10px\">Accuraccy overall remains relatively the same before and after SMOTE was applied, but since this dataset is so imbalanced, accuracy is not as informative.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2192b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "feature_importances = pd.Series(cart_model.feature_importances_, index=X.columns)\n",
    "top_features = feature_importances.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "# Plot the top N features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_features, y=top_features.index)\n",
    "plt.title(f'Top {top_n} Feature Importances from CART Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93837732",
   "metadata": {},
   "source": [
    "**Visualization: Top 10 Feature Importances from CART Model(POST SMOTE)**\n",
    "\n",
    "<p style=\"font-size:10px\">It can be seen that Fraud_Prob has the highest indication towards a fraudulent transaction, but this is because it is an engineered feature taking into account the isFraud flag. It obviously should show the highest indication towards fraud.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">Our attention instead goes to the rest of the 9 features. They are the features provided to us in the dataset that were constructed by Vesta Co. They represent encoded variables referenced in Part A. Future steps will involve accurately understanding these features and what they reference as nothing was written about them in the data description provided on Kaggle.com.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d1019",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = cart_model.predict_proba(X_test)[:, 1]  # Probability scores for the positive class\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve CART Tree')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde2311d",
   "metadata": {},
   "source": [
    "**Visualization: ROC Curve CART Model**\n",
    "\n",
    "This graph displays the trade off between TPR and FPR. Area under curve is 0.7, this indicates that although the model is better at randomly guessing (area under curve = 0.5), there are still improvements to be made with regard to better classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b566862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "average_precision = average_precision_score(y_test, y_probs)\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (AP = {average_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve CART Tree')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4dcc2",
   "metadata": {},
   "source": [
    "**Visualization: Precision-Recall Curve CART Model**\n",
    "\n",
    "<p style=\"font-size:10px\">Displays tradeoff between precision and recall. Average Prevision is seen to be 0.15, and the graph can be seen to dip immensely after 0.4 recall. This indicates that the CART Tree model suffers in classification with regard to capturing even more fraudulent cases. This AP score could be improved as we improve our CART Tree model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da25020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_probs, n_bins=10)\n",
    "\n",
    "# Plot the calibration curve\n",
    "plt.figure()\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Cart_Tree')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Curve CART Tree')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b66fc",
   "metadata": {},
   "source": [
    "**Visualization: Calibration Curve CART Model**\n",
    "\n",
    "<p style=\"font-size:10px\">The Calibration Curve displays predicted probabilities from CART Tree versus truth outcomes. It can be seen that the Cart_Tree line is lower than the Perfectly Calibrated line, showing that the CART Tree model underestimates the probability of a fraudulent transaction. False negative rate is shown to be high.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08967b",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a21491",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "xgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \",  confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b87829",
   "metadata": {},
   "source": [
    "**Statistics: XGBoost Model Performance Analysis**\n",
    "\n",
    "<p style=\"font-size:10px\">It can be seen that just based on accuracy and the classification report that the XGBoost model performs better whether looking at all classes as a whole(macro) or individually. It can be seen that the XGBoost model performs at a slightly higher accuracy, has higher precisioun values across all classifications than CART Tree, has higher F1-scores for classification 1 and 0. These all indicate that XGBoost performs best in this unbalanced high variability environment.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">The macro scores are higher indicating higher accuracy, precision, recall, and F1-scores across both classes.\n",
    "The weighted scores are higher indicating that XGBoost performs better while taking into account class imbalances.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1123b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = xgb_model.predict_proba(X_test)[:, 1]  # Probability scores for the positive class\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve XGBoost')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9614165",
   "metadata": {},
   "source": [
    "**Visualization: ROC Curve XGBoost Model**\n",
    "\n",
    "<p style=\"font-size:10px\">This graph displays the trade off between TPR and FPR. Area under curve is 0.93, this indcates that the XGBoost model has a much higher rate of distinguishing between non-fraud and fraudulent transactions. The curve being relatively close to upper left corner signifies the high TPR of the XGBoost model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1548213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "average_precision = average_precision_score(y_test, y_probs)\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (AP = {average_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve XGBoost')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256684b",
   "metadata": {},
   "source": [
    "**Visualization: Precision-Recall Curve XGBoost Model**\n",
    " \n",
    "<p style=\"font-size:10px\">In the XGBoost model, the average precision is seen to be 0.56, much higher than the CART Tree model. 0.56 mediocre handling of imbalanced data. It can also be seen that the model retains high precision even at low amounts of recall; this is an indication of high confidence in flagging small portionso of transactions as fraud. The model seems to perform much worse as it takes in more data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2169f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_probs, n_bins=10)\n",
    "\n",
    "# Plot the calibration curve\n",
    "plt.figure()\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='XGBoost')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Curve XGboost')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e2f3b",
   "metadata": {},
   "source": [
    "**Visualization: Calibration Curve XGBoost Model**\n",
    "\n",
    "<p style=\"font-size:10px\">It can be seen that the XGBoost model follows the perfectly calibrated line much more closely than the CART Tree Model. This indicates that the XGBoost model predictions better match the truth from the dataset. There are some deviations that go above the perfectly calibrated line, these indicate that as the mean predicted probability increases, the model begins to overestimate transactions as fraud, meaning a high FPR.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653bd3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "feature_importances = pd.Series(xgb_model.feature_importances_, index=X.columns)\n",
    "top_features = feature_importances.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "# Plot the top N features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_features, y=top_features.index)\n",
    "plt.title(f'Top {top_n} Feature Importances from XGBoost Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd98dc0",
   "metadata": {},
   "source": [
    "**Visualization: Top 10 Feature Importances from XGBoost Model**\n",
    "\n",
    "<p style=\"font-size:10px\">It can be seen that the top 10 important features produced from the XGBoost model follow the same trends as the CART Tree Model. The features with highest importances once again turned out to be the encoded features provided by Vesta Co. Once again our goal is to have a better understanding of these features and to apply more analysis and significance on them within our models.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54981c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store xgb_model\n",
    "%store filtered_trainDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b049e7",
   "metadata": {},
   "source": [
    "# Overall Machine Learning Morphism Workflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21871942",
   "metadata": {},
   "source": [
    "X_raw -> Y_pred = F_classification ∘ F_featureEngineering ∘ F_outlierVariance ∘ F_ElementaryDataAnalysis(X_raw) \n",
    "\n",
    "<p style=\"font-size:10px\">The Machine Learning Morphisms of each file are present at the top of each file. It can be seen that once X_raw is fead into ElementaryDataAnalysis that the Machine learning morphism begins and proceeds from each step to the next until a classification ruling is produced. </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d50e8",
   "metadata": {},
   "source": [
    "# Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371772f0",
   "metadata": {},
   "source": [
    "https://github.com/ferrisatassi1/IEEE_Fraud_Detection_Atassi_Hang (Pre-Changes-Branch) NOT MAIN BRANCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f2c0d7",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aece166",
   "metadata": {},
   "source": [
    "<p style=\"font-size:10px\">- Your plan of how to continue or improve your methods/models and the timeline of next steps.</p>\n",
    "\n",
    "-First Week- \n",
    "<p style=\"font-size:10px\">- Our first priority upon submitting this project is to tune hyperparameters within our CART Tree and XGBoost models</p>\n",
    "- <p style=\"font-size:10px\">Work with top 10 feature importances to further tune our models.</p>\n",
    "<p style=\"font-size:10px\">- Understand Preconstructed features in dataset made by Vesta Co.</p>\n",
    "\n",
    "-Second Week-\n",
    "<p style=\"font-size:10px\">- Better our usage of PCA to learn more from it in terms of data cleaning/feature engineering</p>\n",
    "<p style=\"font-size:10px\">- Try out different sampling techniques other than SMOTE to find one that best fits our data</p>\n",
    "<p style=\"font-size:10px\">- Lower data dimensionality </p>\n",
    "\n",
    "-Third Week-\n",
    "<p style=\"font-size:10px\">- Add regularization to XGBoost and CART Tree</p>\n",
    "<p style=\"font-size:10px\">- Calibration to check produced probabilities from model</p>\n",
    "\n",
    "-Fourth Week-\n",
    "<p style=\"font-size:10px\">- Test Model on different sampling sizes/Using data from unused datasets</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd063f",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "<p style=\"font-size:10px\">Bhattacharyya, Siddhartha, et al. “Data Mining for Credit Card Fraud: A Comparative Study.” Decision Support Systems, vol. 50, no. 3, Feb. 2011, pp. 602–613, https://doi.org/10.1016/j.dss.2010.08.008.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">Bolton, Richard, and David Hand. Unsupervised Profiling Methods for Fraud Detection. 2001.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">Castillo, Michelle. “Why Credit Card Fraud Alerts Are Rising, and How Worried You Should Be about Them.” CNBC, 12 Sept. 2024, www.cnbc.com/2024/09/12/why-credit-card-fraud-alerts-are-rising.html.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">Fiore, Ugo, et al. “Using Generative Adversarial Networks for Improving Classification Effectiveness in Credit Card Fraud Detection.” Information Sciences, vol. 479, Apr. 2019, pp. 448–455, https://doi.org/10.1016/j.ins.2017.12.030.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">Foote, Keith D. “A Brief History of Machine Learning - DATAVERSITY.” DATAVERSITY, 3 Dec. 2021, www.dataversity.net/a-brief-history-of-machine-learning/.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">“IEEE-CIS Fraud Detection.” @Kaggle, 2024, www.kaggle.com/competitions/ieee-fraud-detection/leaderboard. Accessed 28 Oct. 2024.</p>\n",
    "\n",
    "<p style=\"font-size:10px\">Xiao, Zhijia. “IEEE-CIS Fraud Detection Based on XGB.” Applied Economics and Policy Studies, 1 Jan. 2024, pp. 1785–1796, https://doi.org/10.1007/978-981-97-0523-8_159. Accessed 28 Oct. 2024.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3888693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16de91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
