{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5669dcc",
   "metadata": {},
   "source": [
    "# Real-time Anomaly Detection in Financial Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16afd4",
   "metadata": {},
   "source": [
    "\n",
    "## Authors and Team\n",
    "\n",
    "- **Author 1**: Ferris Atassi, Developer\n",
    "- **Author 2**: Charles Hang, Developer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de5c70",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f653cd3",
   "metadata": {},
   "source": [
    "### Decisions to be impacted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab363b6d",
   "metadata": {},
   "source": [
    "Our project will impact decisions to accept or reject financial transactions based on suspicion of fraud. More broadly, it will help fraud detection specialists at financial institutions develop tools to detect fraudulent financial transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0100b",
   "metadata": {},
   "source": [
    "### Business Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bedec2",
   "metadata": {},
   "source": [
    "According to global card industry research company Nilson Report, $33 billion was lost to credit card fraud in 2022. Reducing that fraud will lead to savings for  companies, which will sell fewer goods and services to fraudulent buyers and thus incur fewer costs associated with such sales (such as chargebacks). For example, the dataset used in this project was provided by Vesta Corporation, which guarantees that credit card transactions will go through in exchange for a cut of the revenues. Whenever a transaction does turn out to be fraudulent, Vesta is responsible for compensating the seller for the lost volume. Reducing credit card fraud by detecting it when it happens will reduce costs for transaction guarantee companies such as Vesta.\n",
    "\n",
    "Similarly, reducing the number of fraudulent transactions will help consumers by protecting them from accidentally paying for fraudulent transactions and by also lowering how much they pay for goods and services (since providers will not need to raise prices as much to account for fraud costs). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e57103",
   "metadata": {},
   "source": [
    "### Data Assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4fc83d",
   "metadata": {},
   "source": [
    "This project uses the IEEE-CIS dataset, which was used in the IEEE-CIS Fraud Detection competition on Kaggle in 2019. The dataset consists of 590,540 actual credit card transactions spanning a little over six months. The transactions were provided by Vesta Corporation, a leader in the credit card payment guarantee industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc337fe",
   "metadata": {},
   "source": [
    "### Questions and Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b67f6",
   "metadata": {},
   "source": [
    "Question: \n",
    "\n",
    "You mainly focus on known fraud patterns in financial transaction anomaly detection. Do you take measures to identify those unseen abnormal patterns? For example, have you considered introducing adaptive models or online learning to detect new types of fraud in a timely manner?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We have not considered introducing adaptive models or online learning because in the short term, we expect new fraudulent transactions to be similar to the ones in our existing dataset. In an industry application, it would make sense to continuously update the model as new batches of transaction data become available, which would allow the model to adapt to new types of fraud. Of course, this approach would be necessarily reactive to a degree, while adaptive models or online learning based models would allow for more proactive fraud detection, but since the industry generally prefers false negatives than false positives (it is usually better to allow a few fraudulent transactions through rather than deny large numbers of legitimate transactions for customer service reasons), this sort of more aggressive proactive fraud detection might be more trouble than it's worth. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8fc00a",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "When addressing class imbalance, have you evaluated the impact of different features, particularly outliers and high-variance features, on the model’s performance?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Yes, we used Principle Component Analysis (PCA) to analyze the impact of different features on the variance in the data. The PCA output indicated that fraudulent and non-fraudulent transactions had similar values for the principal components, indicating that the variance in feature values was not a major contributor to fraud detection--in other words, there wasn't a high-variance feature with one set of values for fraudulent transactions and another set of values for non-fraudulent transactions. To address outliers, including outliers introduced by high-variance features, we used Mahalonobis distance and Isolation Forest Anomaly Detection to remove outlier values, but due to the unstructured and high-variability factors of the dataset, onl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0bdfd",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Can you share more details on how the outlier detection is done? How do you eliminate the outliers?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Outliers were detected using two methods, Isolation Forest and Mahalonobis Distance outlier detection. Training data that had been cleaned of outliers with Mahalonobis Distance detection was found to be more effective in training an accurate model to detect fraud, so that method was ultimately used to remove outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6d3b2",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "How do you know whether an outlier is a real outlier or a fraud? How to make the rule of removing outliers.\n",
    "\n",
    "Answer:\n",
    "\n",
    "Outliers were detected using two methods, Isolation Forest and Mahalonobis distance detection. Training data that had been cleaned of outliers with Mahalonobis distance detection was found to be more effective in training an accurate model to detect fraud, so that method was ultimately used to remove outliers.\n",
    "\n",
    "Based on our analysis of the data using PCA and simpler techniques, outliers were not found to be more likely to be fraudulent than normal transactions, so removing outliers did not disproportionately remove fraudulent transactions. Because of that, our expectation was that outlier removal would not reduce our model's ability to detect fraudulent transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69f5c33",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Why you choose left join two datasets? What is the differences between the identity dataset and the transaction dataset.\n",
    "\n",
    "Answer:\n",
    "\n",
    "The transaction dataset had all of our transactions, while the identity dataset had identifying information about the parties involved in each transaction. The transaction dataset was left joined to the identity dataset so that all transaction data would be preserved, even if it mean that some transactions lacked identity data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ab453",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "In your project, outlier detection is addressed as a supervised learning problem, but some research suggests that it should be approached as an unsupervised learning task since the proportion of fraud transactions are extremly low in most cases. Have you considered handling this problem in that way?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We actually addressed outlier detection as an unsupervised learning problem, not a supervised learning problem. Both of the outlier detection techniques we used, Isolation Forest and Mahalonobis Distance, were unsupervised techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff82a2",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "I wonder if your project can be extended from classification to prediction. In other words, can we predict roughly when and where the next frauds are going to happen given the history of frauds? That would be great for practical purposes : ) \n",
    "\n",
    "Answer:\n",
    "\n",
    "We expect that our model could be used to detect future fraudulent transactions by predicting which transactions in future batches of transaction data are fraudulent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e6666f",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Can you explain how you validated your model and ensured it would perform well on new, unseen data?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We divided our transaction data into training data to train our model and test data for validation. For the model, the test data was \"new, unseen\" data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556232a6",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Have you ever considered how the dominated value of a feature influences the model training?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We had some features with one dominant value (for example, the large majority of our card transactions were for Visa cards, and essentially all of our transactions took place in the U.S.). Our understanding of the literature is that just because one or more features has a single dominant view, that doesn't mean the feature has to be transformed in any particular way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc77aba",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "While dealing with categorical features, do you use sparse encoding like one-hot encoding? Since I noticed you have mail locations in the dataset, and one hot encoding will lead to a very sparse data.\n",
    "\n",
    "Answer:\n",
    "\n",
    "No, we did not use any encoding methods to transform our categorical feature data. Some of the data in the original dataset may have already been encoded using one-hot encoding, however.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155e0f3",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "The outliers are an essential component in fraud detection....since the one with outliers could be potentially called as fraud transactions. So my question is would you still do outlier detection and remove them?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Based on our analysis of the dataset, outlier transactions were not disproportionately likely to be fraudulent, and thus removing them did not reduce our ability to detect fraudulent transactions. It would be much easier to detect fraudulent transactions if they were all outliers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1103bf64",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Why did you choose the metrics you did that lead you to make an XGBoost model?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Our assessment of the literature indicated that XGBoost is one of the most commonly used methods for fraud detection using machine learning, since it has some of the highest accuracy scores for similar problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ea74e",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "So which of the outlier detection methods did you think were more accurate?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Mahalonobis Distance outlier detection resulted in significantly stronger model performance than Isolation Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effac05a",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Can you elaborate on your decision to focus on tree-based models? You mentioned that the performed better in the literature with regard to accuracy, but do you think there might be other advantages of non-tree classifiers?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Tree-based models were just one option we chose to use in our project; we also used other models such as XGBoost. We used tree-based models because they have an established history of being effective in detecting fraudulent transactions in industry. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619d01d",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "It looks like your dataset is extremely imbanlance, how do you deal with this problem?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We used models (XGBoost, Isolation Forest, SMOTE) which have a proven history of being effective in making predictions on data in imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcdcc0d",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Are there more creative sampling techniques that can be used to make the data set more balanced in training?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Yes, oversampling is a common method of making an imbalanced dataset more balanced in training. SMOTE is one oversampling method we used to make our dataset more balanced for our CART Tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32193d80",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Why did the XGBoost model do better? How did it beter handle the class imbalance?\n",
    "\n",
    "Answer:\n",
    "\n",
    "XGBoost is an ensemble model, meaning that it combines multiple decision trees, which makes it more effective at handling imbalanced data. Additionally, XGBoost's nature as an iterative boosting model also helps it handle imbalanced data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3c679",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Does the label distribution shift after removing outliers? Intuitively, fraud transactions may be outliers in the feature space.\n",
    "\n",
    "Answer:\n",
    "\n",
    "PCA indicates that fraudulent and non-fraudulent transactions have similar principal component distributions, which implies that outliers are not disproportionately fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313d36c",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "Castillo, Michelle. “Why Credit Card Fraud Alerts Are Rising, and How Worried You Should Be about Them.” CNBC, 12 Sept. 2024, www.cnbc.com/2024/09/12/why-credit-card-fraud-alerts-are-rising.html.\n",
    "\n",
    "“IEEE-CIS Fraud Detection.” @Kaggle, 2024, www.kaggle.com/competitions/ieee-fraud-detection/leaderboard. Accessed 28 Oct. 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99566a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
