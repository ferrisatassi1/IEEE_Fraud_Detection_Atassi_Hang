{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQguXUt0cJPD",
        "outputId": "753b8a1e-a626-468e-f06a-de331e33788e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Standard Libraries\n",
        "import math\n",
        "from sklearn.utils import resample\n",
        "import pickle\n",
        "import warnings\n",
        "# Scientific Computing and Data Manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from scipy import stats\n",
        "from scipy.spatial.distance import mahalanobis\n",
        "\n",
        "# Machine Learning Models and Utilities\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import (\n",
        "    IsolationForest,\n",
        "    RandomForestClassifier,\n",
        "    StackingClassifier,\n",
        "    VotingClassifier\n",
        ")\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.feature_selection import RFE, SelectFromModel, mutual_info_classif\n",
        "from sklearn.linear_model import LogisticRegression, LassoCV\n",
        "from sklearn.metrics import (\n",
        "    ConfusionMatrixDisplay,\n",
        "    accuracy_score,\n",
        "    average_precision_score,\n",
        "    balanced_accuracy_score,\n",
        "    brier_score_loss,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    log_loss,\n",
        "    matthews_corrcoef,\n",
        "    precision_recall_curve,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    auc\n",
        ")\n",
        "from sklearn.model_selection import (\n",
        "    GridSearchCV,\n",
        "    HalvingRandomSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    RepeatedStratifiedKFold,\n",
        "    cross_val_score,\n",
        "    learning_curve,\n",
        "    train_test_split\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, label_binarize\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "\n",
        "# Imbalanced Learning\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Parallelization\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Google Colab Utilities\n",
        "from google.colab import drive, files\n",
        "\n",
        "# Warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Google Drive Mount\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/IEEE_dataset/voting_model_RandomForest.pkl', 'rb') as f:\n",
        "    voting_model_RandomForest = pickle.load(f)\n",
        "with open('/content/drive/My Drive/IEEE_dataset/voting_model_LASSO.pkl', 'rb') as f:\n",
        "    voting_model_LASSO = pickle.load(f)\n",
        "with open('/content/drive/My Drive/IEEE_dataset/one_class_svm_models.pkl', 'rb') as f:\n",
        "    svm_models = pickle.load(f)\n",
        "filtered_trainDF = pd.read_pickle('/content/drive/My Drive/IEEE_dataset/filtered_trainDF.pkl')"
      ],
      "metadata": {
        "id": "mq5cu30fcp7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = filtered_trainDF.drop(columns=['isFraud'])  # Features\n",
        "y = filtered_trainDF['isFraud']  # Target\n",
        "\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'datetime64[ns]' or 'Timestamp' in col:\n",
        "        X[col] = pd.to_datetime(X[col], errors='coerce').astype('int64')  # Convert to timestamp (int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "label_encoders = {}\n",
        "for col in X_train.columns:  # Fit on X_train\n",
        "    if X_train[col].dtype == 'object' or isinstance(X_train[col].dtype, pd.CategoricalDtype):\n",
        "        le = LabelEncoder()\n",
        "        # Fit the encoder on the combined unique values from both train and test\n",
        "        # to ensure all possible values are seen during fitting\n",
        "        le.fit(pd.concat([X_train[col], X_test[col]]).astype(str).unique())\n",
        "        X_train[col] = le.transform(X_train[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "# Transform X_test using the fitted label encoders\n",
        "for col in X_test.columns:\n",
        "    if col in label_encoders:\n",
        "        X_test[col] = label_encoders[col].transform(X_test[col].astype(str))\n",
        "\n",
        "# Impute missing values separately for training and test sets\n",
        "# using strategies fitted on the training data\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype in ['float64', 'int64']:\n",
        "        # Numeric columns: fill with training mean\n",
        "        impute_value = X_train[col].mean()\n",
        "        X_train[col] = X_train[col].fillna(impute_value)\n",
        "        X_test[col] = X_test[col].fillna(impute_value)\n",
        "    else:\n",
        "        # Non-numeric columns: fill with training mode\n",
        "        impute_value = X_train[col].mode()[0]\n",
        "        X_train[col] = X_train[col].fillna(impute_value)\n",
        "        X_test[col] = X_test[col].fillna(impute_value)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0iuy-DumoANi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict for balanced models (Random Forest and Lasso)\n",
        "expected_features = voting_model_RandomForest.estimators_[0][1].get_booster().feature_names\n",
        "\n",
        "# Select only those features from X_test\n",
        "X_test_subset = X_test[expected_features]\n",
        "\n",
        "y_pred_rf = voting_model_RandomForest.predict(X_test_subset)\n",
        "y_pred_lasso = voting_model_LASSO.predict(X_test_subset)\n",
        "\n",
        "# Predict for the One-Class SVM model\n",
        "# Assuming svm_models was also trained with the same subset of features\n",
        "y_pred_svm = svm_models.predict(X_test_subset)\n",
        "\n",
        "# ... (rest of the code remains the same)\n",
        "# Select only those features from X_test\n",
        "X_test_subset = X_test[expected_features]\n",
        "\n",
        "y_pred_rf = voting_model_RandomForest.predict(X_test_subset)\n",
        "y_pred_lasso = voting_model_LASSO.predict(X_test_subset)\n",
        "\n",
        "# Predict for the One-Class SVM model\n",
        "# Assuming svm_models was also trained with the same subset of features\n",
        "y_pred_svm = svm_models.predict(X_test_subset)\n",
        "\n",
        "# ... (rest of the code remains the same)\n",
        "# Convert SVM predictions to 0/1 (0 for inliers, 1 for outliers)\n",
        "y_pred_svm = np.where(y_pred_svm == 1, 0, 1)  # Assuming 1 is inlier, -1 is outlier in SVM\n",
        "\n",
        "# Combine predictions using majority voting\n",
        "y_pred_combined = np.zeros_like(y_pred_rf)\n",
        "for i in range(len(y_pred_rf)):\n",
        "    votes = [y_pred_rf[i], y_pred_lasso[i], y_pred_svm[i]]\n",
        "    y_pred_combined[i] = max(set(votes), key=votes.count)  # Majority vote\n",
        "\n",
        "# Evaluate the combined predictions\n",
        "print(\"Combined Model Performance:\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred_combined)}\")\n",
        "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_combined)}\")\n",
        "print(classification_report(y_test, y_pred_combined))\n",
        "\n",
        "# Confusion matrix\n",
        "cm_combined = confusion_matrix(y_test, y_pred_combined)\n",
        "print(f\"Combined Model Confusion Matrix: \\n{cm_combined}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "9iAFEOcCiJV7",
        "outputId": "bc30beb8-4fad-43dc-ba6f-a7b466d6ecb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'XGBClassifier' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e1e259aabe30>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict for balanced models (Random Forest and Lasso)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexpected_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoting_model_RandomForest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Select only those features from X_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexpected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'XGBClassifier' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}