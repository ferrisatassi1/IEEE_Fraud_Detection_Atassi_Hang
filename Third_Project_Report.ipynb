{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5669dcc",
   "metadata": {},
   "source": [
    "# Real-time Anomaly Detection in Financial Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16afd4",
   "metadata": {},
   "source": [
    "\n",
    "## Authors and Team\n",
    "\n",
    "- **Author 1**: Ferris Atassi, Developer\n",
    "- **Author 2**: Charles Hang, Developer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de5c70",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f653cd3",
   "metadata": {},
   "source": [
    "### Decisions to be impacted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab363b6d",
   "metadata": {},
   "source": [
    "Our project will impact decisions to accept or reject financial transactions based on suspicion of fraud. More broadly, it will help fraud detection specialists at financial institutions develop tools to detect fraudulent financial transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0100b",
   "metadata": {},
   "source": [
    "### Business Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bedec2",
   "metadata": {},
   "source": [
    "According to global card industry research company Nilson Report, $33 billion was lost to credit card fraud in 2022. Reducing that fraud will lead to savings for  companies, which will sell fewer goods and services to fraudulent buyers and thus incur fewer costs associated with such sales (such as chargebacks). For example, the dataset used in this project was provided by Vesta Corporation, which guarantees that credit card transactions will go through in exchange for a cut of the revenues. Whenever a transaction does turn out to be fraudulent, Vesta is responsible for compensating the seller for the lost volume. Reducing credit card fraud by detecting it when it happens will reduce costs for transaction guarantee companies such as Vesta.\n",
    "\n",
    "Similarly, reducing the number of fraudulent transactions will help consumers by protecting them from accidentally paying for fraudulent transactions and by also lowering how much they pay for goods and services (since providers will not need to raise prices as much to account for fraud costs). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e57103",
   "metadata": {},
   "source": [
    "### Data Assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4fc83d",
   "metadata": {},
   "source": [
    "This project uses the IEEE-CIS dataset, which was used in the IEEE-CIS Fraud Detection competition on Kaggle in 2019. The dataset consists of 590,540 actual credit card transactions spanning a little over six months. The transactions were provided by Vesta Corporation, a leader in the credit card payment guarantee industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc337fe",
   "metadata": {},
   "source": [
    "### Questions and Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b67f6",
   "metadata": {},
   "source": [
    "Question: \n",
    "\n",
    "You mainly focus on known fraud patterns in financial transaction anomaly detection. Do you take measures to identify those unseen abnormal patterns? For example, have you considered introducing adaptive models or online learning to detect new types of fraud in a timely manner?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We have not considered introducing adaptive models or online learning because in the short term, we expect new fraudulent transactions to be similar to the ones in our existing dataset. In an industry application, it would make sense to continuously update the model as new batches of transaction data become available, which would allow the model to adapt to new types of fraud. Of course, this approach would be necessarily reactive to a degree, while adaptive models or online learning based models would allow for more proactive fraud detection, but since the industry generally prefers false negatives than false positives (it is usually better to allow a few fraudulent transactions through rather than deny large numbers of legitimate transactions for customer service reasons), this sort of more aggressive proactive fraud detection might be more trouble than it's worth. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8fc00a",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "When addressing class imbalance, have you evaluated the impact of different features, particularly outliers and high-variance features, on the model’s performance?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Yes, we used Principle Component Analysis (PCA) to analyze the impact of different features on the variance in the data. The PCA output indicated that fraudulent and non-fraudulent transactions had similar values for the principal components, indicating that the variance in feature values was not a major contributor to fraud detection--in other words, there wasn't a high-variance feature with one set of values for fraudulent transactions and another set of values for non-fraudulent transactions. To address outliers, including outliers introduced by high-variance features, we used Mahalonobis distance and Isolation Forest Anomaly Detection to remove outlier values. Due to the unstructured and high-variability factors of the dataset, only Isolation Forest produced results worth mentioning/applying to our training dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0bdfd",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Can you share more details on how the outlier detection is done? How do you eliminate the outliers?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Outliers were detected using two methods, Isolation Forest and Mahalonobis Distance outlier detection. Training data that had been cleaned of outliers with Isolation Forest Anomaly Detection was found to be more effective in training an accurate model to detect fraud, so that method was ultimately used to remove outliers. As mentioned before our data has many features that are uncorrelated, leading to Mahalnobis Distance Outlier Detection underperforming by a significant margin (nearly 0 outliers found).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6d3b2",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "How do you know whether an outlier is a real outlier or a fraud? How to make the rule of removing outliers.\n",
    "\n",
    "Answer:\n",
    "\n",
    "Outliers were detected using two methods, Isolation Forest and Mahalonobis distance detection. As noted before Mahalnobis is underperforming in this format, thus Isolation Forest Anomaly Detection was able to remove the most amount of outliers. This is because of the random nature of Isolation Forest in which random features are selected, with random splits. We removed the Fraud_Flag from the anomaly detection method, so that the method would focus solely on feature anomalies, and have less emphasis on the fact that a fraudulent transaction is an outlier itself. \n",
    "\n",
    "Based on our analysis of the data using PCA and simpler techniques, outliers were not found to be more likely to be fraudulent than normal transactions, so removing outliers did not disproportionately remove fraudulent transactions. Because of that, our expectation was that outlier removal would not reduce our model's ability to detect fraudulent transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69f5c33",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Why you choose left join two datasets? What is the differences between the identity dataset and the transaction dataset.\n",
    "\n",
    "Answer:\n",
    "\n",
    "The transaction dataset had all of our transactions, while the identity dataset had identifying information about the parties involved in each transaction. The transaction dataset was left joined to the identity dataset so that all transaction data would be preserved, even if it mean that some transactions lacked identity data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ab453",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "In your project, outlier detection is addressed as a supervised learning problem, but some research suggests that it should be approached as an unsupervised learning task since the proportion of fraud transactions are extremly low in most cases. Have you considered handling this problem in that way?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We actually addressed outlier detection as an unsupervised learning problem, not a supervised learning problem. Both of the outlier detection techniques we used, Isolation Forest and Mahalonobis Distance, were unsupervised techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff82a2",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "I wonder if your project can be extended from classification to prediction. In other words, can we predict roughly when and where the next frauds are going to happen given the history of frauds? That would be great for practical purposes : ) \n",
    "\n",
    "Answer:\n",
    "\n",
    "We expect that our model could be used to detect future fraudulent transactions by predicting which transactions in future batches of transaction data are fraudulent. This would require ongoing transaction data to update our model, since the model is too dependent on analyzing transaction features to predict future transactions just on the history of fraudulent activity. Our data needs to be trained on transaction data to judge whether future transactions are fraudulent or not. That said, if that training data is available based on future transactions, we would be able to predict future frauds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e6666f",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Can you explain how you validated your model and ensured it would perform well on new, unseen data?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We divided our transaction data into training data to train our model and test data for validation. For the model, the test data was \"new, unseen\" data. We are currently at the point of adjusting our repeated nested cross validation results utilizing our training data, our end goal is to have an evaluation on this test set to see how model performs on unseen data, especially with regard to MSE.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556232a6",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Have you ever considered how the dominated value of a feature influences the model training?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We had some features with one dominant value (for example, the large majority of our card transactions were for Visa cards, and essentially all of our transactions took place in the U.S.). Our understanding of the literature is that just because one or more features has a single dominant view, that doesn't mean the feature has to be transformed in any particular way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc77aba",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "While dealing with categorical features, do you use sparse encoding like one-hot encoding? Since I noticed you have mail locations in the dataset, and one hot encoding will lead to a very sparse data.\n",
    "\n",
    "Answer:\n",
    "\n",
    "Our project instead utilizes Label Encoder rather than one-hot encoding. Label Encoding instead assigns each category to be a different integer. It also works best with the models we utilized later in the project (CART Tree) because they are not sensetive to this format of encoding. Due to the models splitting on feature thresholds instead of relationships in between encoded values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155e0f3",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "The outliers are an essential component in fraud detection....since the one with outliers could be potentially called as fraud transactions. So my question is would you still do outlier detection and remove them?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Based on our analysis of the dataset, outlier transactions were not disproportionately likely to be fraudulent, and thus removing them did not reduce our ability to detect fraudulent transactions. It would be much easier to detect fraudulent transactions if they were all outliers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1103bf64",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Why did you choose the metrics you did that lead you to make an XGBoost model?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Our assessment of the literature indicated that XGBoost is one of the most commonly used methods for fraud detection using machine learning, since it has some of the highest accuracy scores for similar problems. Our initial guess was to utilize a CART-Tree model due to our problem being very similar to the classification problems CART-Tree solves. After producing results, our group saw that although the the model was pefforming well, it was overfitting the data and having too many false postives to be deemed accurate. After researching online we saw that the XGBoost model excelled in scenarios like our project. The XGBoost model took into account the complexity of our data, and introduces regularizion measures to combat it. It also utilized feature_importance in its judgement which is another factor of our data we thought was incredibly useful for potential stakeholders to see. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ea74e",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "So which of the outlier detection methods did you think were more accurate?\n",
    "\n",
    "Answer:\n",
    "\n",
    "As noted before Isolation Forest Anomaly Detection was far more accurate and was able to identify plenty of transactions considered to be anomalies while ignoring the fraud flag. Our Mahalbosis distance outlier detection method produced an output of nearly 0 outlier detected, showing that the data might be too complex with  uncorrelated features for Mahalanobis Distance to be of use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effac05a",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Can you elaborate on your decision to focus on tree-based models? You mentioned that the performed better in the literature with regard to accuracy, but do you think there might be other advantages of non-tree classifiers?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Tree-based models were just one option we chose to use in our project; we also used other models such as XGBoost. We used tree-based models because they have an established history of being effective in detecting fraudulent transactions in industry. \n",
    "\n",
    "We looked at non-tree classifiers (SVM, Logistic Regeression, k-NN, etc..) but found our data to be too unstructured, complex, unbalanced, and large for these models to assess our data accurately.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619d01d",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "It looks like your dataset is extremely imbanlance, how do you deal with this problem?\n",
    "\n",
    "Answer:\n",
    "\n",
    "We used models (XGBoost, Isolation Forest, SMOTE) which have a proven history of being effective in making predictions on data in imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcdcc0d",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Are there more creative sampling techniques that can be used to make the data set more balanced in training?\n",
    "\n",
    "Answer:\n",
    "\n",
    "Yes, oversampling is a common method of making an imbalanced dataset more balanced in training. SMOTE is one oversampling method we used to make our dataset more balanced for our CART Tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32193d80",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Why did the XGBoost model do better? How did it beter handle the class imbalance?\n",
    "\n",
    "Answer:\n",
    "\n",
    "XGBoost is an ensemble model, meaning that it combines multiple decision trees, which makes it more effective at handling imbalanced data. Additionally, XGBoost's nature as an iterative boosting model also helps it handle imbalanced data. CART-Tree is prone to overfitting the data, which is a major issue given the low occurrence of fraudulent transactions. Also much of our data contined missing values, which XGBoost handles implicitly. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3c679",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "Does the label distribution shift after removing outliers? Intuitively, fraud transactions may be outliers in the feature space.\n",
    "\n",
    "Answer:\n",
    "\n",
    "PCA indicates that fraudulent and non-fraudulent transactions have similar principal component distributions, which implies that outliers are not disproportionately fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313d36c",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "Castillo, Michelle. “Why Credit Card Fraud Alerts Are Rising, and How Worried You Should Be about Them.” CNBC, 12 Sept. 2024, www.cnbc.com/2024/09/12/why-credit-card-fraud-alerts-are-rising.html.\n",
    "\n",
    "“IEEE-CIS Fraud Detection.” @Kaggle, 2024, www.kaggle.com/competitions/ieee-fraud-detection/leaderboard. Accessed 28 Oct. 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99566a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
