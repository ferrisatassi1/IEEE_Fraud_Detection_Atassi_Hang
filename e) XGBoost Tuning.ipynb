{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15f8d8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import scipy\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e78e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r xgb_model\n",
    "%store -r filtered_trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbe350a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data: Define features (X) and target (y)\n",
    "X = filtered_trainDF.drop(columns=['isFraud'])  # Features (drop the target column)\n",
    "y = filtered_trainDF['isFraud']  # Target\n",
    "\n",
    "# Handle Timestamp columns (convert them to numeric if necessary)\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'datetime64[ns]' or 'Timestamp' in str(X[col].dtype):\n",
    "        X[col] = X[col].astype('int64')  # Convert datetime to int (timestamps)\n",
    "\n",
    "# Convert categorical columns to numeric using Label Encoding (for simplicity)\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object' or isinstance(X[column].dtype, pd.CategoricalDtype):\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column].astype(str))\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Replace infinite or very large values with NaN\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN values for numeric columns with column mean, and categorical columns with mode\n",
    "for col in X.columns:\n",
    "    if X[col].dtype in ['float64', 'int64']:  # For numeric columns\n",
    "        X[col] = X[col].fillna(X[col].mean())  # Assign the filled result back to the column\n",
    "    else:  # For categorical columns, fill with the most frequent value\n",
    "        X[col] = X[col].fillna(X[col].mode()[0])  # Assign the filled result back to the column\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1453cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model (ensure `use_label_encoder` is not used)\n",
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d75af",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "feature_importances = pd.Series(xgb_model.feature_importances_, index=X.columns)\n",
    "top_features = feature_importances.sort_values(ascending=False).head(top_n).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X[top_features]\n",
    "pca = PCA(n_components=2)  # Change the number of components as needed\n",
    "X_pca = pca.fit_transform(X_reduced)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='coolwarm', alpha=0.5)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA of Top Important Features')\n",
    "plt.colorbar(label='Target (Fraud/Non-Fraud)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e5759d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9208df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
